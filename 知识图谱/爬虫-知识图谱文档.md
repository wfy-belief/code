## get started

> 1. 运行 `主页面爬取.py`
> 2. 运行 `论文_作者关系构造.py`
> 3. 运行 `引用-被引用关系构造.py`
> 4. 运行 `主文章其它关系构造.py`
>
> <font color=red>涉及节点查找，建议按照顺序执行代码，实例化传递对应数据库密码即可，例如：`my_noe4j = MyNeo4j(password=mypassword) 代码皆使用多线程。`</font>

# 数据获取

## 代码维护日志

> - <font color='#348498'><b>2021年1月29日</b></font> 修改 `neo4j_methods` 关键参数和关键方法为**私有**
>
> - <font color='#348498'><b>2021年1月29日</b></font> 增加函数功能模块，支持查找存在节点并添加关系或直接新建节点添加关系
>
> - <font color='#348498'><b>2021年1月29日</b></font> 增加和修改 `neo4j_methods` 自定义模块 **函数注解** **参数注解**
>
> - <font color='#348498'><b>2021年1月16日</b></font> 修改自定义类 `neo4j_methods` 创建节点部分参数，支持**多标签**
>
> - <font color='#348498'><b>2021年1月16日</b></font> 增加引用和被引用关系
>
> - <font color='#348498'><b>2021年1月15日</b></font> 上一个版本中，自定义类 `neo4j_methods` 创建节点，并没有查询该节点是否存在。换句话说，就是每次创建关系都`新建两个节点`与`一个关系`这种是不正确的，正确的做法应当为：`首先查询该节点是否存在，如果存在，返回节点信息，不存在则创建。`
>
> - <font color='#348498'><b>2021年1月15日</b></font> 完善论文著作关系。
>
>   paper节点属性与解释（<font color='red'>至记录日期</font>）：
>
>   | 属性名称 |               解释               |    异常值     |
>   | :------: | :------------------------------: | :-----------: |
>   |   <id>   |        neo4j内置唯一标识         |      无       |
>   |    id    | 网页/论文的唯一标识/查找节点使用 | 无/id一定存在 |
>   | abstract |             论文摘要             | 部分文章缺失  |
>   | keywords |            论文关键词            | 部分文章缺失  |
>   |  score   |           论文综合得分           |   一定存在    |
>   |   name   |             论文名称             |   一定存在    |
>
>   person节点属性与解释（<font color='red'>至记录日期</font>）：
>
>   | 属性名称 |       解释        |  异常值  |
>   | :------: | :---------------: | :------: |
>   |   <id>   | neo4j内置唯一标识 |    无    |
>   |   name   |   作者/人物姓名   |    无    |
>   |    id    |   作者唯一标识    | 存在缺失 |

数据获取的网站为 [Aminer](https://www.aminer.cn/search/pub?q=Cyberspace%20security&t=b) 

## 主页面paper数据获取

主页面paper数据获取，可以点击下一页，然后 `F12` 检查网页信息。可以发现一个数据的接口 `https://apiv2.aminer.cn/n?a=SEARCH__searchapi.SearchPubsCommon___` 

- 请求方式为：POST 请求
- 提交的是数据： payload

基本爬取方法：

1. 构造请求头
2. 定义`POST`请求数据
3. 使用`requests.post`提交请求数据
4. 得到返回的json数据

## paper数据的简单清洗

返回的是json数据，但是需要注意的是，网页端极有可能返回的是字节流，而不是Unicode编码。

1. 所以使用 `response.content.decode('utf-8')` 重新编码信息。

2. 通过 `json.loads(json_str)` 把json字符串加载为python的dict类型。

3. > 执行
   >
   > ```python
   > with open('./paper_data.json', 'w', encoding='utf-8') as file:
   >     json.dump(json_dict, file, indent=4, ensure_ascii=False)
   > ```
   >
   > 保存网页爬取的数据。
   >
   > 其中参数解释：
   >
   > - json_dict是python的字典数据类型
   > - file是文件的IO操作
   > - indent控制文本的缩进
   > - ensure_ascii是否能够保存中英文
   
## 引用reference数据获取

获取引用数据的json字符串

> - 目标网址：'https://api.aminer.cn/api/pub/ref/{id}/offset/{offset}/size/{size}'
> - id是对应paper的唯一标识，参照维护日志。示例：53e9b945b7602d970453061a
> - offset是数据的起始位置。默认0.
> - size数据的条数，默认30.
> - 请求方式：GET请求。
> - headers：需要。
> - 函数解释：给定id和数据量的大小，返回json字符串

```python
def get_page_reference(id='53e9b945b7602d970453061a', offset=0, size=30):
    '''
    获取引用信息
    '''
    url = f'https://api.aminer.cn/api/pub/ref/{id}/offset/{offset}/size/{size}'

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36 Edg/87.0.664.66'
    }

    responses = requests.get(url=url,
                             headers=headers,
                             )

    return responses.text
```

1. > - ensure_ascii是否能够保存中英文

## 被引用cited数据获取

获取引用数据的json字符串

> - 请求网址'https://apiv2.aminer.cn/magic?a=getCited__publication.CitedByPid___'
> - id是对应paper的唯一标识，参照维护日志。示例：53e9b945b7602d970453061a
> - offset是数据的起始位置。默认0.
> - size数据的条数，默认30.
> - 请求方式：POST请求。
> - headers：需要。
> - 函数解释：给定id和数据量的大小，返回json字符串

```python
def get_page_cited(id='53e9b945b7602d970453061a', offset=0, size=30):
    '''
    获取被引用信息
    '''
    post_data = [{
        "action": "publication.CitedByPid",
        "parameters": {
            "ids": [id],
            "offset":offset, "size":size}}]
    url = 'https://apiv2.aminer.cn/magic?a=getCited__publication.CitedByPid___'

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36 Edg/87.0.664.66'
    }

    responses = requests.post(url=url,
                              headers=headers,
                              json=post_data)

    return responses.text
```

# 知识图谱

## bolt协议

[Bolt](https://www.sofastack.tech/projects/sofa-rpc/bolt/) 协议一个基于 TCP 的自定义的协议，相比 HTTP 来说，性能更好，在蚂蚁金服内部，大量的 RPC 都是采用 Bolt 协议来进行通信： * [基本使用](https://www.sofastack.tech/projects/sofa-rpc/bolt-usage) * [调用方式](https://www.sofastack.tech/projects/sofa-rpc/invoke-type) * [超时控制](https://www.sofastack.tech/projects/sofa-rpc/bolt-timeout) * [泛化调用](https://www.sofastack.tech/projects/sofa-rpc/generic-invoke) * [序列化协议](https://www.sofastack.tech/projects/sofa-rpc/serialization) * [自定义线程池](https://www.sofastack.tech/projects/sofa-rpc/custom-threadpool)

docker 运行命令

进行简单的关系抽取。

## 关系构造

| source | labels | relationship   | target   | labels             | 查找节点      |
| ------ | ------ | -------------- | -------- | ------------------ | ------------- |
| 论文   | paper  | author         | 作者     | person             | (True, True)  |
| 论文   | paper  | reference      | 参考文献 | (reference, paper) | (True, True)  |
| 论文   | paper  | cited          | 被引用   | (cited, paper)     | (True, True)  |
| 论文   | paper  | 属性相关（略） | 对应属性 | (property)         | (True, False) |
| 论文   | paper  | 索引相关（略） | 对应索引 | (index)            | (True, False) |

> - 论文属性和索引，每篇文章都具有且唯一，所以不需要查找节点。

## neo4j数据查询

查找有关系的数据

```cypher
MATCH p=({name:'Survey on cyberspace security.'})-->() RETURN p
```

```cypher
MATCH p=({id:'56d863d0dabfae2eee90cac4'})-->() RETURN p
```

查找三层

```cypher
match data=(na:paper{name:'Survey on cyberspace security.'})-[*1..3]-() return data
```

```cypher
match data=(na:paper{name:'A Survey of Malware Detection Techniques'})-[*1..3]-() return data
```

```cypher
match data=(na:paper{name:'Survey on cyberspace security.'})-[*1..3]-() return data limit 100
```

